#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children no
\language american
\language_package default
\inputencoding utf8
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement class
\float_alignment class
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008080
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content true
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Title
METR data modelling
\end_layout

\begin_layout Author
Jonas Moss
\end_layout

\begin_layout Itemize
Goal:
 Modeling of METR trajectory.
\end_layout

\begin_layout Itemize
Method:
 2PL with direct modeling of everything.
 
\end_layout

\begin_layout Itemize
The basic 2PL:
 What and why
\end_layout

\begin_layout Itemize
Adding dates to stuff.
\end_layout

\begin_layout Itemize
Potential bla bla bla?
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Short overview:
 METR trend extrapolation is important.
 The way METR does it in their paper good but somewhat ad hoc.
 Here's a principled alternative that doubles down on item response theory.
 
\end_layout

\begin_layout Standard
Lets have a look at an idealized variant of the METR data,
 which looks roughly like this:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left[\begin{array}{ccccccc}
\text{Model} & \text{Task ID} & \text{Success} & \text{Attempts} & \text{Date} & \text{Family} & \text{Human time}\\
\text{o3} & 1 & 3 & 4 & 2025-04-16 & a\\
\text{Opus 4} & 2 & 3 & 4 & 2025-05-22 & b\\
\vdots\\
\text{Opus 3} & 3 & 3 & 4 & 2024-03-04 & c\\
\text{o1} & 4 & 3 & 4 & 2024-12-05 & d
\end{array}\right]
\]

\end_inset

So there are a bunch of (model,task) pairs that have have.
\end_layout

\begin_layout Section
2PL model
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $i,j,k$
\end_inset

 be the index of the model,
 the task,
 and the independent run of the task.
 The binary variables 
\begin_inset Formula $Y_{ijk}$
\end_inset

 indicate task success.
 We need to model the probability of task completion.
 Our 2PL model family looks like
\begin_inset Formula 
\[
P(Y_{ijk}=1)=\sigma[\beta_{j}(\theta_{i}-\delta_{j})],
\]

\end_inset

where 
\begin_inset Formula $\sigma=1/(1+e^{-x})$
\end_inset

 is the logistic,
 
\begin_inset Formula $\delta_{j}$
\end_inset

 is the item difficulty,
 
\begin_inset Formula $\theta_{i}$
\end_inset

 is model ability,
 and 
\begin_inset Formula $\beta_{j}>0$
\end_inset

 is the task discrimination.
 
\end_layout

\begin_layout Standard
This is called a 2-parameter logistic model (2PL) in item response theory.
\end_layout

\begin_layout Itemize
The ability or skill parameters 
\begin_inset Formula $\theta_{i}$
\end_inset

 for model 
\begin_inset Formula $i$
\end_inset

 (e.g.,
 GPT-4o) is small if the model is a poor and large if its good.
\end_layout

\begin_layout Itemize
If the discrimination parameter is large:
 A positive difference 
\begin_inset Formula $\theta_{i}-\delta_{j}$
\end_inset

 will cause the resulting probability to be large as well,
 a negative difference will cause the resulting probability to be small.
 
\end_layout

\begin_deeper
\begin_layout Itemize
Its easiest to think of this from a human perspective.
 Lets say you have a have a high school calculus problem such as 
\begin_inset Quotes eld
\end_inset

what is the derivative of 
\begin_inset Formula $\sin x$
\end_inset


\begin_inset Quotes erd
\end_inset

.
 The ok students will virtually always know the answers to this problem,
 i.e.,
 the students that paid attention at all.
 The other students will almost always fail.
 There is little room for randomness,
 so the discrimination is large.
 
\end_layout

\end_deeper
\begin_layout Standard
From these we get a posterior for the relevant parameters.
 Now we have time horizons 
\begin_inset Formula $t_{j}$
\end_inset

 for each task and release dates 
\begin_inset Formula $d_{i}$
\end_inset

 for the models as well.
 We treat those as deterministic.
 We'd like to estimate
\begin_inset Formula 
\[
p_{i}(t)=P(\text{model }i\text{ succeeds on task of length }t).
\]

\end_inset

Suppose 
\begin_inset Formula $\beta,\theta,\delta$
\end_inset

 are known first of course.
 We need to map 
\begin_inset Formula $t_{j}$
\end_inset

 to 
\begin_inset Formula $(\beta_{j},\delta_{j})$
\end_inset

 then.
 The problem is that we do not know this mapping or if it even exists in a reasonable way 
\begin_inset Formula $\beta_{j},\delta_{j}$
\end_inset

.
 It would be possible to connect these,
 maybe,
 by having more participants and potentially censored time-to-completion distributions.
 This could potentially make data-collecting for METR easier too.
 
\end_layout

\begin_layout Standard
Anyway,
 lets just think of the easiest version:
\begin_inset Formula 
\[
p_{i}(t_{j})=P(Y_{ijk}|\beta_{j},\delta_{j}).
\]

\end_inset

Here we get 
\emph on
something
\emph default
.
 Will it look reasonable,
 e.g.,
 monotonic?
 Probably not,
 due to different 
\begin_inset Formula $\beta_{j}$
\end_inset

 and 
\begin_inset Formula $\delta_{j}$
\end_inset

 behaving erratically.
\end_layout

\begin_layout Section
More modelling
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\theta_{i} & = & f(d_{i})+\epsilon_{i}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Section
Joint 2PL model
\end_layout

\begin_layout Standard
Lets use the 2PL model but also include 
\begin_inset Formula 
\begin{eqnarray*}
\delta_{j} & = & f(t_{j})+u_{j},\quad\beta_{j}=g(t_{j})+v_{j},
\end{eqnarray*}

\end_inset

for some reasonable functions 
\begin_inset Formula $f,g$
\end_inset

.
\end_layout

\begin_layout Standard
Two reasonable choices are 
\begin_inset Formula $\delta_{j}=\log t_{j}+u_{j}$
\end_inset

 and 
\begin_inset Formula $\beta_{j}$
\end_inset

 constant.
 In this case we get very close to the METR model actually,
 only difference is we have a random effect in difficulty,
 which does look reasonable.
 
\begin_inset Formula 
\begin{eqnarray*}
P(Y_{ijk}=1) & = & \sigma[\beta_{j}(\theta_{i}-\delta_{j})],\\
\delta_{j} & = & a_{\delta}+b_{\delta}\log t_{j}+u_{j},\\
\beta_{j} & = & a_{\beta}+b_{\beta}\log t_{j}+v_{j}.
\end{eqnarray*}

\end_inset

And then we have 
\begin_inset Formula $S_{\theta}(t)=P(Y=1|t,\theta)=\int\sigma[\beta_{j}(\theta-\delta_{j})]dp(u)dp(v)$
\end_inset

.
 Ok so what do we want here?
 We want to match 
\begin_inset Formula $(d_{i},\theta_{i})$
\end_inset

 to some kind of 
\begin_inset Formula $t$
\end_inset

.
 And what we have is actually 
\begin_inset Formula $S_{i}$
\end_inset

.
 So we want to do model 
\begin_inset Formula $S_{g(d)}(t)$
\end_inset

 somehow,
 and that is easies through 
\begin_inset Formula $\sum_{i=1}^{n}(\theta_{i}-g(d))^{2}$
\end_inset

 no?
\end_layout

\begin_layout Section
Monotone regression model
\end_layout

\end_body
\end_document
